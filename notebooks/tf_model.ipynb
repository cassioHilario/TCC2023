{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1s3hNBDjPq87-5H1ZaK0SWK9U1kcMwfKi",
      "authorship_tag": "ABX9TyM++0f3Kk25PnXEVrw+hEAr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cassioHilario/TCC2023/blob/main/notebooks/tf_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yFsJ8wJpRMXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! pip install tensorflow scikit-learn pandas numpy pickle5"
      ],
      "metadata": {
        "id": "W_XPRzQs3TMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install nltk"
      ],
      "metadata": {
        "id": "OQrskyqT4p7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import nltk\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "import pickle5 as pickle"
      ],
      "metadata": {
        "id": "gWfHwQNF3WkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../base/amostra_base_v10.1.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "2k9hu4ue3YRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['frase', 'label']]\n",
        "df['sentiment'] = df['label'].apply(lambda x: 'positive' if x == 1\n",
        "                                    else 'negative')\n",
        "df = df[['frase', 'sentiment']]\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "nWBSfieK4EE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['frase'])\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(df['frase'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=10000, truncating='post')"
      ],
      "metadata": {
        "id": "SgnBy1Se4XWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_labels = pd.get_dummies(df['sentiment']).values"
      ],
      "metadata": {
        "id": "YciNlMh05wkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, sentiment_labels, test_size=0.3)"
      ],
      "metadata": {
        "id": "n4sLGw2A52VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(5000, 100, input_length=100))\n",
        "model.add(Conv1D(64, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "nDX9m3fp53jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "-1lTKLrK58bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
        "print(\"Accuracy:\", accuracy_score(np.argmax(y_test, axis=-1), y_pred))"
      ],
      "metadata": {
        "id": "mxVQa1EK58-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make predictions\n",
        "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(np.argmax(y_test, axis=-1), y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generate classification report\n",
        "class_report = classification_report(np.argmax(y_test, axis=-1), y_pred, target_names=['negative', 'positive'])\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(np.argmax(y_test, axis=-1), y_pred)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(conf_matrix, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(conf_matrix, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if normalize:\n",
        "        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.tight_layout()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = conf_matrix.max() / 2.\n",
        "    for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
        "        plt.text(j, i, format(conf_matrix[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plot_confusion_matrix(conf_matrix, classes=['negative', 'positive'])"
      ],
      "metadata": {
        "id": "bBWTTWWrhm28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate precision-recall curve\n",
        "precision, recall, _ = precision_recall_curve(np.argmax(y_test, axis=-1), y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='b', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.grid()\n",
        "\n",
        "# Calculate and print area under the curve (AUC) for precision-recall curve\n",
        "pr_auc = auc(recall, precision)\n",
        "print(\"Precision-Recall AUC:\", pr_auc)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Generate ROC curve\n",
        "fpr, tpr, _ = roc_curve(np.argmax(y_test, axis=-1), y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.grid()\n",
        "\n",
        "# Calculate and print area under the curve (AUC) for ROC curve\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(\"ROC AUC:\", roc_auc)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aY3NBcd1jp4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('nominal_agreement_analysis_model_v2.h5')\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "EbfQN94a5_xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "model = keras.models.load_model('/content/nominal_agreement_analysis_model_v2.h5')\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "metadata": {
        "id": "Xt8awqrU6C3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    # Tokenize and pad the input text\n",
        "    text_sequence = tokenizer.texts_to_sequences([text])\n",
        "    text_sequence = pad_sequences(text_sequence, maxlen=100)\n",
        "\n",
        "    # Make a prediction using the trained model\n",
        "    predicted_rating = model.predict(text_sequence)[0]\n",
        "    if np.argmax(predicted_rating) == 0:\n",
        "        return 'Negative'\n",
        "    elif np.argmax(predicted_rating) == 1:\n",
        "        return 'Positive'"
      ],
      "metadata": {
        "id": "DEWampAg6FA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "6cfIDVxJ4fbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"O carro é bonita\"\n",
        "predicted_sentiment = predict_sentiment(text_input)\n",
        "print(predicted_sentiment)"
      ],
      "metadata": {
        "id": "xGlGNj166LUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"O carro é bonito\"\n",
        "predicted_sentiment = predict_sentiment(text_input)\n",
        "print(predicted_sentiment)"
      ],
      "metadata": {
        "id": "TZKSd7bF6VST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"O carro é bonitos\"\n",
        "predicted_sentiment = predict_sentiment(text_input)\n",
        "print(predicted_sentiment)"
      ],
      "metadata": {
        "id": "o00pJrju6WxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"O carro é bonitas\"\n",
        "predicted_sentiment = predict_sentiment(text_input)\n",
        "print(predicted_sentiment)"
      ],
      "metadata": {
        "id": "hGUaNsb66YKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}